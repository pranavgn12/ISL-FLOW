# Indian Sign Language (ISL) Recognition & Smart Typing
<br/>

![Technologies](https://skillicons.dev/icons?i=py,tensorflow,opencv)
![MediaPipe](https://github.com/pranavgn12/ISL-FLOW/blob/main/media_pipe.png?raw=true) <br/><br/>
A real-time computer vision application that translates Indian Sign Language (ISL) hand gestures into text. This project leverages **MediaPipe** for robust hand landmark extraction and a custom **Neural Network** trained on ISL gestures (A-Z, 0-9).
It features a **"Smart Typer"** interface with auto-complete, clipboard integration, and high-quality UI rendering, designed to act as an assistive communication tool.



## ðŸš€ Key Features

* **Real-Time Detection:** Instantly recognizes single and double-handed ISL gestures via webcam.
* **Robust Landmark Tracking:** Uses MediaPipe to extract 42 hand landmarks (21 per hand), making it resilient to lighting changes.
* **Smart Auto-Complete:** Suggests words based on the current character sequence (e.g., typing "GOO" suggests "GOOD").
* **Hands-Free Mode:** "Hold-to-type" functionality allows typing without touching the keyboard.
* **Clipboard Integration:** One-key shortcut to copy constructed sentences to the system clipboard.
* **High-Quality UI:** Anti-aliased text rendering using Pillow (PIL) for a polished look.



## ðŸ› ï¸ Technical Architecture

### 1. Data Pipeline
Instead of using raw images (CNNs), this project uses a **Landmark-based approach** for higher efficiency and speed.
* **Input:** Live video frame from OpenCV.
* **Extraction:** MediaPipe Hands detects hands and extracts $(x, y)$ coordinates for 21 points per hand.
* **Normalization:** Data is normalized and sorted (Left Hand vs. Right Hand) to ensure consistent input vectors.
* **Vectorization:** The 42 points are flattened into a **(1, 84)** feature vector.

### 2. Model Structure (MLP)
The classifier is a Feed-Forward Neural Network (Multi-Layer Perceptron) built with TensorFlow/Keras:
* **Input Layer:** 84 neurons (42 landmarks $\times$ 2 coordinates).
* **Hidden Layers:**
    * Dense (128 neurons, ReLU activation) + Dropout (0.2)
    * Dense (64 neurons, ReLU activation) + Dropout (0.2)
* **Output Layer:** Softmax activation (Classes: A-Z, 0-9).



## ðŸ“‚ Project Structure

```bash
ISL-Flow/
â”‚
â”œâ”€â”€ data/                 Data set used https://www.kaggle.com/datasets/prathumarikeri/indian-sign-language-isl
â”‚   â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ B/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ create_dataset.py     # Script to convert raw images -> CSV landmarks
â”œâ”€â”€ train_model.py        # Script to train the Neural Network
â”œâ”€â”€ inference.py          # Main application for real-time detection
â”œâ”€â”€ isl_keypoints.csv     # Generated feature dataset (CSV)
â”œâ”€â”€ isl_model.h5          # Pre-trained Model file
â”œâ”€â”€ label_mapping.npy     # Saved label classes
â”œâ”€â”€ arial.ttf             # (Optional) Font file for UI
â”œâ”€â”€ requirements.txt      # Python dependencies
```
> Python, TensorFlow, and OpenCV icons: [skillicons.dev](https://skillicons.dev)
